# -*- coding: utf-8 -*-
"""Data Mining and ML Assignment 2 Fin 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12tkifcin0fYkSK6dx6mB2OaklDxEidx_
"""



"""# Import Libraries"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd # for dataframe creation
import numpy as np # for numerical calculations
import matplotlib.pyplot as plt # for visualization
import seaborn as sns # for visualization
import plotly.express as px #for visualizaiton
# %matplotlib inline
from sklearn.cluster import KMeans #clustering algo

"""# Load Dataset"""

df = pd.read_csv('/content/drive/MyDrive/datasets/heart.csv') #reading the csv file using pandas and storing in dataframe df

df.head(3)



"""```
Age: age of the patient [years]
Sex: sex of the patient [M: Male, F: Female]
ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]
RestingBP: resting blood pressure [mm Hg]
Cholesterol: serum cholesterol [mm/dl]
FastingBS: fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]
RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]
MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]
ExerciseAngina: exercise-induced angina [Y: Yes, N: No]
Oldpeak: oldpeak = ST [Numeric value measured in depression]
ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]
HeartDisease: output class [1: heart disease, 0: Normal]
```

# EDA

## Correlation analysis
"""

plt.figure(figsize=(9,6))
correlation = df.corr()
sns.heatmap(correlation, annot= True, cmap = 'RdBu')



"""## Countplots"""



px.histogram(data_frame = df, x = 'Sex', color = 'HeartDisease', title="Distribution of Heart Diseases over Sex",barmode="group")

"""**Sex : male patients had a significantly higher rate of illness than women had**"""

px.histogram(data_frame = df, x = 'MaxHR', color = 'HeartDisease', title="Distribution of Heart Diseases over Maximum Heart rate",barmode="group")

"""**"MaxHR" : about 75% of people with a maximum heart rate of 120 had a heart disease;**"""



px.histogram(data_frame = df, x = 'FastingBS', color = 'HeartDisease', title="Distribution of Heart Diseases over Fasting Blood Sugar",barmode="group")

"""**"Fasting BS" : about 80% of people with a fasting blood sugar above 120 mg/dl had a heart disease**"""



df.columns

sns.histplot(data = df ,x = 'RestingECG', hue = 'HeartDisease',palette = 'Set1')
plt.title("Distribution of Heart Diseases over RestingECG")



px.histogram(df, x="ChestPainType", color="HeartDisease",title="Distribution of Heart Diseases over Chest Pain Type",barmode="group")





"""## KDE Plot"""

# Age

sns.kdeplot(data=df, x='Age',hue="HeartDisease", fill=True,palette=["#8000ff","#da8829"], alpha=.5, linewidth=0)

sns.kdeplot(data=df, x='Oldpeak',hue="HeartDisease", fill=True,palette=["#8000ff","#da8829"], alpha=.5, linewidth=0)

sns.kdeplot(data=df, x='MaxHR',hue="HeartDisease", fill=True,palette=["#8000ff","#da8829"], alpha=.5, linewidth=0)

"""## Visualize Raw Dataset"""

plt.figure(figsize=(6, 6))
sns.scatterplot(data=df, x= df['Age'], y =df['Cholesterol'])
plt.title('Visualize Raw Dataset')

plt.figure(figsize=(6, 6))
sns.scatterplot(data=df, x= df['Oldpeak'], y =df['MaxHR'])
plt.title('Visualize Raw Dataset')

plt.figure(figsize=(6, 6))
sns.scatterplot(data=df, x= df['RestingBP'], y =df['MaxHR'])
plt.title('Visualize Raw Dataset')











"""# Data Cleaning / Pre Processing"""

df_copy = df.copy()

#very important to drop the target if it is present
df_copy.drop(columns = ['HeartDisease'],inplace=True)
df_copy.head(5)

target_ = df.iloc[:,-1]

data = df_copy[['Age', 'Cholesterol']]
data2 = df_copy[['Oldpeak', 'MaxHR']]
data3 = df_copy[['Oldpeak', 'Age']]
data4 = df_copy[['Age', 'RestingBP']]
data5 = df_copy[['Cholesterol', 'MaxHR']]

"""# Elbow Method and Silhouette Plot"""

dfin = df_copy[['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']]

!pip install yellowbrick  
from yellowbrick.cluster import KElbowVisualizer
from sklearn.cluster import KMeans

cs = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, random_state = 0)
    kmeans.fit(dfin)
    cs.append(kmeans.inertia_)
    
plt.plot(range(1, 11), cs)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('CS')
plt.show()

# Instantiate the clustering model and visualizer
km = KMeans(random_state=42)
visualizer = KElbowVisualizer(km, k=(1,10))
 
visualizer.fit(dfin)        # Fit the data to the visualizer
visualizer.show()

"""**We can see that at K=3 there is a sharp kink which indicates that K=3 is optimal number of clusters**"""

import matplotlib.pyplot as plt
from yellowbrick.cluster import SilhouetteVisualizer

fig, ax = plt.subplots(3, 2, figsize=(15,8))
for i in [2, 3, 4, 5]:
    '''
    Create KMeans instances for different number of clusters
    '''
    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)
    q, mod = divmod(i, 2)
    '''
    Create SilhouetteVisualizer instance with KMeans instance
    Fit the visualizer
    '''
    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])
    visualizer.fit(dfin)

"""# 1. Age vs Chol KMEANS

## Standard Scaling
"""

# Standardize the data
from sklearn.preprocessing import StandardScaler
X_std = StandardScaler().fit_transform(data)

"""## Apply KMeans"""

# Run local implementation of kmeans Here we tested 3 clusters
km = KMeans(n_clusters=3,
    n_init=10, max_iter=300)
km.fit(X_std)
centroids = km.cluster_centers_

X_std

labels_ = km.predict(X_std)
labels_

# plot the 3 clusters
plt.scatter(
    X_std[labels_ == 0, 0], X_std[labels_ == 0, 1],
    s=50, c='lightgreen',
    marker='s', edgecolor='black',
    label='cluster 1'
)

plt.scatter(
    X_std[labels_ == 1, 0], X_std[labels_ == 1, 1],
    s=50, c='orange',
    marker='o', edgecolor='black',
    label='cluster 2'
)

plt.scatter(
    X_std[labels_ == 2, 0], X_std[labels_ == 2, 1],
    s=50, c='lightblue',
    marker='v', edgecolor='black',
    label='cluster 3'
)

# plot the centroids
plt.scatter(
    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],
    s=250, marker='*',
    c='red', edgecolor='black',
    label='centroids'
)
plt.legend(scatterpoints=1)
plt.grid()
plt.show()

"""## Check quality of classification"""

# check how many of the samples were correctly labeled
correct_labels = sum(target_ == labels_)

print("Result: %d out of %d samples were correctly labeled." % (correct_labels, target_.size))

#km.predict([[103,3044,	2,	88]])

#print(labels)

"""## Plot the clustered data - Age vs Chol"""

fig, ax = plt.subplots(figsize=(6, 6))
plt.scatter(X_std[labels_ == 0, 0], X_std[labels_ == 0, 1],
            c='green', label='cluster 1')
plt.scatter(X_std[labels_ == 1, 0], X_std[labels_ == 1, 1],
            c='blue', label='cluster 2')
plt.scatter(X_std[labels_ == 2, 0], X_std[labels_ == 2, 1],
            c='yellow', label='cluster 3')

plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,
            c='r', label='centroid')
plt.legend()
plt.xlim([-3, 4])
plt.ylim([-3, 4])
plt.xlabel('age')
plt.ylabel('chol')
plt.title('Visualization of clustered data', fontweight='bold')
ax.set_aspect('equal');

"""## Silhouette Score """

from sklearn.metrics import silhouette_score
score = silhouette_score(X_std, km.labels_, metric='euclidean')

score

"""# 2. Oldpeak vs MaxHR KMEANS

## Standard Scaling
"""

# Standardize the data
from sklearn.preprocessing import StandardScaler
X_std = StandardScaler().fit_transform(data2)

"""## Apply KMeans"""

# Run local implementation of kmeans Here we tested 3 clusters
km = KMeans(n_clusters=3, random_state = 42)
km.fit(X_std)
centroids = km.cluster_centers_

X_std

# labels_ are equivalent to calling fit(x) then predict
labels_ = km.predict(X_std)
labels_



"""## Check quality of classification"""

# check how many of the samples were correctly labeled
correct_labels = sum(target_ == labels_)

print("Result: %d out of %d samples were correctly labeled." % (correct_labels, target_.size))



#print(labels)

"""## Plot the clustered data - Oldpeak vs MaxHR"""

fig, ax = plt.subplots(figsize=(6, 6))
plt.scatter(X_std[labels_ == 0, 0], X_std[labels_ == 0, 1],
            c='red', label='cluster 1')
plt.scatter(X_std[labels_ == 1, 0], X_std[labels_ == 1, 1],
            c='orange', label='cluster 2')
plt.scatter(X_std[labels_ == 2, 0], X_std[labels_ == 2, 1],
            c='lightgreen', label='cluster 3')

plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,
            c='black', label='centroid')
plt.legend()
plt.xlim([-3, 4])
plt.ylim([-3, 4])
plt.xlabel('Oldpeak')
plt.ylabel('MaxHR')
plt.title('Visualization of clustered data', fontweight='bold')
ax.set_aspect('equal');



"""## Silhouette Score """

from sklearn.metrics import silhouette_score
score = silhouette_score(X_std, km.labels_, metric='euclidean')

score





"""# 3. Oldpeak vs Age KMEANS

## Standard Scaling
"""

# Standardize the data
from sklearn.preprocessing import StandardScaler
X_std = StandardScaler().fit_transform(data3)

"""## Apply KMeans"""

# Run local implementation of kmeans Here we tested 3 clusters
km = KMeans(n_clusters=3, random_state = 42)
km.fit(X_std)
centroids = km.cluster_centers_

X_std

# labels_ are equivalent to calling fit(x) then predict
labels_ = km.predict(X_std)
labels_



"""## Check quality of classification"""

# check how many of the samples were correctly labeled
correct_labels = sum(target_ == labels_)

print("Result: %d out of %d samples were correctly labeled." % (correct_labels, target_.size))



#print(labels)

"""## Plot the clustered data - Oldpeak vs Age"""

fig, ax = plt.subplots(figsize=(6, 6))
plt.scatter(X_std[labels_ == 0, 0], X_std[labels_ == 0, 1],
            c='red', label='cluster 1')
plt.scatter(X_std[labels_ == 1, 0], X_std[labels_ == 1, 1],
            c='orange', label='cluster 2')
plt.scatter(X_std[labels_ == 2, 0], X_std[labels_ == 2, 1],
            c='yellow', label='cluster 3')

plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,
            c='black', label='centroid')
plt.legend()
plt.xlim([-3, 4])
plt.ylim([-3, 4])
plt.xlabel('Oldpeak')
plt.ylabel('Age')
plt.title('Visualization of clustered data', fontweight='bold')
ax.set_aspect('equal');



"""## Silhouette Score """

from sklearn.metrics import silhouette_score
score = silhouette_score(X_std, km.labels_, metric='euclidean')

score





"""# 4. Age vs RestingBP KMEANS

## Standard Scaling
"""

# Standardize the data
from sklearn.preprocessing import StandardScaler
X_std = StandardScaler().fit_transform(data4)

"""## Apply KMeans"""

# Run local implementation of kmeans Here we tested 3 clusters
km = KMeans(n_clusters=3, random_state = 42)
km.fit(X_std)
centroids = km.cluster_centers_
labels_ = km.predict(X_std)

X_std

# labels_ are equivalent to calling fit(x) then predict
labels_ = km.predict(X_std)
labels_



"""## Check quality of classification"""

# check how many of the samples were correctly labeled
correct_labels = sum(target_ == labels_)

print("Result: %d out of %d samples were correctly labeled." % (correct_labels, target_.size))



#print(labels)

"""## Plot the clustered data -  Age vs RestingBP """

fig, ax = plt.subplots(figsize=(6, 6))
plt.scatter(X_std[labels_ == 0, 0], X_std[labels_ == 0, 1],
            c='red', label='cluster 1')
plt.scatter(X_std[labels_ == 1, 0], X_std[labels_ == 1, 1],
            c='orange', label='cluster 2')
plt.scatter(X_std[labels_ == 2, 0], X_std[labels_ == 2, 1],
            c='yellow', label='cluster 3')

plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,
            c='black', label='centroid')
plt.legend()
plt.xlim([-3, 4])
plt.ylim([-3, 4])
plt.xlabel('Age')
plt.ylabel('RestingBP')
plt.title('Visualization of clustered data', fontweight='bold')
ax.set_aspect('equal');



"""## Silhouette Score """

from sklearn.metrics import silhouette_score
score = silhouette_score(X_std, km.labels_, metric='euclidean')

score





"""# 5. Cholesterol vs MaxHR KMEANS

## Standard Scaling
"""

# Standardize the data
from sklearn.preprocessing import StandardScaler
X_std = StandardScaler().fit_transform(data5)

"""## Apply KMeans"""

# Run local implementation of kmeans Here we tested 3 clusters
km = KMeans(n_clusters=3, random_state = 42)
km.fit(X_std)
centroids = km.cluster_centers_

X_std

# labels_ are equivalent to calling fit(x) then predict
labels_ = km.predict(X_std)
labels_



"""## Check quality of classification"""

# check how many of the samples were correctly labeled
correct_labels = sum(target_ == labels_)

print("Result: %d out of %d samples were correctly labeled." % (correct_labels, target_.size))



#print(labels)

"""## Plot the clustered data - Cholesterol vs MaxHR"""

fig, ax = plt.subplots(figsize=(6, 6))
plt.scatter(X_std[labels_ == 0, 0], X_std[labels_ == 0, 1],
            c='red', label='cluster 1')
plt.scatter(X_std[labels_ == 1, 0], X_std[labels_ == 1, 1],
            c='orange', label='cluster 2')
plt.scatter(X_std[labels_ == 2, 0], X_std[labels_ == 2, 1],
            c='yellow', label='cluster 3')

plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=300,
            c='black', label='centroid')
plt.legend()
plt.xlim([-3, 4])
plt.ylim([-3, 4])
plt.xlabel('Cholesterol')
plt.ylabel('MaxHR')
plt.title('Visualization of clustered data', fontweight='bold')
ax.set_aspect('equal');



"""## Silhouette Score """

from sklearn.metrics import silhouette_score
score = silhouette_score(X_std, km.labels_, metric='euclidean')

score